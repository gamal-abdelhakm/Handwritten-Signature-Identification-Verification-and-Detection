{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b496ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "179e351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageHelpers:\n",
    "    def __init__(self):\n",
    "        self.sift_object = cv2.xfeatures2d.SIFT_create()\n",
    "        \n",
    "    def gray(self, image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return gray\n",
    "\n",
    "    def features(self, image):\n",
    "        keypoints, descriptors = self.sift_object.detectAndCompute(image, None)\n",
    "        return [keypoints, descriptors]\n",
    "\n",
    "\n",
    "class BOVHelpers:\n",
    "    def __init__(self, n_clusters=20):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans_obj = KMeans(n_clusters=n_clusters)\n",
    "        self.kmeans_ret = None\n",
    "        self.descriptor_vstack = None\n",
    "        self.mega_histogram = None\n",
    "        self.clf = SVC()\n",
    "\n",
    "    def cluster(self):\n",
    "        self.kmeans_ret = self.kmeans_obj.fit_predict(self.descriptor_vstack)\n",
    "\n",
    "    def developVocabulary(self, n_images, descriptor_list):\n",
    "        self.mega_histogram = np.array([np.zeros(self.n_clusters) for i in range(n_images)])\n",
    "        old_count = 0\n",
    "        for i in range(n_images):\n",
    "            l = len(descriptor_list[i])\n",
    "            for j in range(l):\n",
    "                idx = self.kmeans_ret[old_count + j]\n",
    "                self.mega_histogram[i][idx] += 1\n",
    "            old_count += l\n",
    "        print(\"Vocabulary Histogram Generated\")\n",
    "\n",
    "    def standardize(self, std=None):\n",
    "        if std is None:\n",
    "            self.scale = StandardScaler().fit(self.mega_histogram)\n",
    "            self.mega_histogram = self.scale.transform(self.mega_histogram)\n",
    "        else:\n",
    "            print(\"STD not none. External STD supplied\")\n",
    "            self.mega_histogram = std.transform(self.mega_histogram)\n",
    "\n",
    "    def formatND(self, l):\n",
    "        vStack = np.array(l[0])\n",
    "        for remaining in l[1:]:\n",
    "            vStack = np.vstack((vStack, remaining))\n",
    "        self.descriptor_vstack = vStack.copy()\n",
    "        return\n",
    "\n",
    "    def train(self, train_labels):\n",
    "        print(\"Training SVM\")\n",
    "        print(self.clf)\n",
    "        print(\"Train labels\", train_labels)\n",
    "        self.clf.fit(self.mega_histogram, train_labels)\n",
    "        print(\"Training completed\")\n",
    "\n",
    "    def predict(self, iplist):\n",
    "        predictions = self.clf.predict(iplist)\n",
    "        return predictions\n",
    "\n",
    "    def plotHist(self, vocabulary=None):\n",
    "        print(\"Plotting histogram\")\n",
    "        if vocabulary is None:\n",
    "            vocabulary = self.mega_histogram\n",
    "\n",
    "        x_scalar = np.arange(self.n_clusters)\n",
    "        y_scalar = np.array([abs(np.sum(vocabulary[:, h], dtype=np.int32)) for h in range(self.n_clusters)])\n",
    "\n",
    "        print(y_scalar)\n",
    "\n",
    "        plt.bar(x_scalar, y_scalar)\n",
    "        plt.xlabel(\"Visual Word Index\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(\"Complete Vocabulary Generated\")\n",
    "        plt.xticks(x_scalar + 0.4, x_scalar)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class FileHelpers:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def getFiles(self, path):\n",
    "        imlist = {}\n",
    "        count = 0\n",
    "        for each in os.listdir(path):\n",
    "            print(\" #### Reading image category \", each, \" ##### \")\n",
    "            imlist[each] = []\n",
    "            for imagefile in os.listdir(path + '/' + each):\n",
    "                print(\"Reading file \", imagefile)\n",
    "                im = cv2.imread(path + '/' + each + '/' + imagefile, 0)\n",
    "                imlist[each].append(im)\n",
    "                count += 1\n",
    "\n",
    "        return [imlist, count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d3b17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from glob import glob \n",
    "import argparse\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25344e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOV:\n",
    "    def __init__(self, no_clusters):\n",
    "        self.no_clusters = no_clusters\n",
    "        self.train_path = None\n",
    "        self.test_path = None\n",
    "        self.im_helper = ImageHelpers()\n",
    "        self.bov_helper = BOVHelpers(no_clusters)\n",
    "        self.file_helper = FileHelpers()\n",
    "        self.images = None\n",
    "        self.trainImageCount = 0\n",
    "        self.train_labels = np.array([])\n",
    "        self.name_dict = {}\n",
    "        self.descriptor_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def trainModel(self):\n",
    "        # read file. prepare file lists.\n",
    "        self.images, self.trainImageCount = self.file_helper.getFiles(self.train_path)\n",
    "        # extract SIFT Features from each image\n",
    "        label_count = 0 \n",
    "        for word, imlist in self.images.items():\n",
    "            self.name_dict[str(label_count)] = word\n",
    "            print (\"Computing Features for \", word)\n",
    "            for im in imlist:\n",
    "                # cv2.imshow(\"im\", im)\n",
    "                # cv2.waitKey()\n",
    "                self.train_labels = np.append(self.train_labels, label_count)\n",
    "                kp, des = self.im_helper.features(im)\n",
    "                self.descriptor_list.append(des)\n",
    "\n",
    "            label_count += 1\n",
    "\n",
    "\n",
    "        # perform clustering\n",
    "        self.bov_helper.formatND(self.descriptor_list)\n",
    "        self.bov_helper.cluster()\n",
    "        self.bov_helper.developVocabulary(n_images = self.trainImageCount, descriptor_list=self.descriptor_list)\n",
    "\n",
    "        # show vocabulary trained\n",
    "        self.bov_helper.plotHist()\n",
    "\n",
    "        self.bov_helper.standardize()\n",
    "        self.bov_helper.train(self.train_labels)\n",
    "\n",
    "\n",
    "    def recognize(self,test_img, test_image_path=None):\n",
    "\n",
    "        kp, des = self.im_helper.features(test_img)\n",
    "        # print kp\n",
    "        print (des.shape)\n",
    "\n",
    "        # generate vocab for test image\n",
    "        vocab = np.array( [[ 0 for i in range(self.no_clusters)]])\n",
    "        vocab = np.array(vocab, 'float32')\n",
    "        # locate nearest clusters for each of \n",
    "        # the visual word (feature) present in the image\n",
    "        \n",
    "        # test_ret =<> return of kmeans nearest clusters for N features\n",
    "        test_ret = self.bov_helper.kmeans_obj.predict(des)\n",
    "        # print test_ret\n",
    "\n",
    "        # print vocab\n",
    "        for each in test_ret:\n",
    "            vocab[0][each] += 1\n",
    "\n",
    "        #print (vocab)\n",
    "\n",
    "        # Scale the features\n",
    "        vocab = self.bov_helper.scale.transform(vocab)\n",
    "        # predict the class of the image\n",
    "        lb = self.bov_helper.clf.predict(vocab)\n",
    "        # print \"Image belongs to class : \", self.name_dict[str(int(lb[0]))]\n",
    "        return lb\n",
    "\n",
    "\n",
    "\n",
    "    def testModel(self):\n",
    "        correctClassifications = 0\n",
    "        self.testImages, self.testImageCount = self.file_helper.getFiles(self.test_path)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for word, imlist in self.testImages.items():\n",
    "            print (\"processing \" ,word)\n",
    "            for im in imlist:\n",
    "                # print imlist[0].shape, imlist[1].shape\n",
    "                print (im.shape)\n",
    "                cl = self.recognize(im)\n",
    "                print (cl)\n",
    "                predictions.append({\n",
    "                    'image':im,\n",
    "                    'class':cl,\n",
    "                    'object_name':self.name_dict[str(int(cl[0]))]\n",
    "                    })\n",
    "\n",
    "                if(self.name_dict[str(int(cl[0]))]==word):\n",
    "                    correctClassifications = correctClassifications + 1\n",
    "\n",
    "        print(\"Test Accuracy = \" + str((correctClassifications/self.testImageCount) * 100))\n",
    "        #print (predictions)\n",
    "        for each in predictions:\n",
    "            # cv2.imshow(each['object_name'], each['image'])\n",
    "            # cv2.waitKey()\n",
    "            # cv2.destroyWindow(each['object_name'])\n",
    "            # \n",
    "            plt.imshow(cv2.cvtColor(each['image'], cv2.COLOR_GRAY2RGB))\n",
    "            plt.title(each['object_name'])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225d23d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train_path TRAIN_PATH] [--test_path TEST_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Jimmy\\AppData\\Roaming\\jupyter\\runtime\\kernel-d54dccb3-2d03-40b0-b0ac-b0e93f670516.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# parse cmd args\n",
    "parser = argparse.ArgumentParser(description=\" Bag of visual words example\")\n",
    "parser.add_argument('--train_path',default=\"images\\\\train\", action=\"store\", dest=\"train_path\")\n",
    "parser.add_argument('--test_path',default=\"images\\\\test\", action=\"store\", dest=\"test_path\")\n",
    "args = vars(parser.parse_args())\n",
    "print(args)\n",
    "bov = BOV(no_clusters=5)\n",
    "# set training paths\n",
    "bov.train_path = args['train_path'] \n",
    "# set testing paths\n",
    "bov.test_path = args['test_path'] \n",
    "# train the model\n",
    "bov.trainModel()\n",
    "# test model\n",
    "bov.testModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "624b93f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train_path TRAIN_PATH] [--test_path TEST_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Jimmy\\AppData\\Roaming\\jupyter\\runtime\\kernel-d54dccb3-2d03-40b0-b0ac-b0e93f670516.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\" Bag of visual words example\")\n",
    "parser.add_argument('--train_path',default=\"images\\\\train\", action=\"store\", dest=\"train_path\")\n",
    "parser.add_argument('--test_path',default=\"images\\\\test\", action=\"store\", dest=\"test_path\")\n",
    "args = vars(parser.parse_args())\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b01d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
